{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-31T15:35:46.361895Z","iopub.status.busy":"2024-07-31T15:35:46.360986Z","iopub.status.idle":"2024-07-31T15:35:49.151214Z","shell.execute_reply":"2024-07-31T15:35:49.149961Z","shell.execute_reply.started":"2024-07-31T15:35:46.361768Z"},"trusted":true},"outputs":[],"source":["\n","import os\n","import pandas as pd\n","\n","from scipy.sparse import hstack, csr_matrix\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{},"source":["## Data Validation\n","\n","* Explore the first 10.000 rows of the dataset to determine data preparation strategy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-31T15:48:33.455588Z","iopub.status.busy":"2024-07-31T15:48:33.455162Z","iopub.status.idle":"2024-07-31T15:48:33.53364Z","shell.execute_reply":"2024-07-31T15:48:33.532441Z","shell.execute_reply.started":"2024-07-31T15:48:33.455556Z"},"trusted":true},"outputs":[],"source":["train_data = pd.read_csv(\"c:\\Users\\Abhinav sinha\\OneDrive\\Desktop\\OSData_Train .csv\", nrows=10000)  # read a few rows to start"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-31T15:35:49.273351Z","iopub.status.busy":"2024-07-31T15:35:49.272959Z","iopub.status.idle":"2024-07-31T15:35:49.289915Z","shell.execute_reply":"2024-07-31T15:35:49.288755Z","shell.execute_reply.started":"2024-07-31T15:35:49.273317Z"},"trusted":true},"outputs":[],"source":["train_data['Category'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-31T15:36:16.120182Z","iopub.status.busy":"2024-07-31T15:36:16.119745Z","iopub.status.idle":"2024-07-31T15:36:16.129371Z","shell.execute_reply":"2024-07-31T15:36:16.128042Z","shell.execute_reply.started":"2024-07-31T15:36:16.120147Z"},"trusted":true},"outputs":[],"source":["train_data['EvidenceRole'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-31T15:40:09.141609Z","iopub.status.busy":"2024-07-31T15:40:09.141204Z","iopub.status.idle":"2024-07-31T15:40:09.152154Z","shell.execute_reply":"2024-07-31T15:40:09.15082Z","shell.execute_reply.started":"2024-07-31T15:40:09.141578Z"},"trusted":true},"outputs":[],"source":["train_data['CountryCode'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data.iloc[:,:15].head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data.iloc[:, [0, 9] + list(range(15, 30))].head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data.iloc[:, [0, 9] + list(range(30, 45))].head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Count summary of Incident Grade classes\n","train_data['IncidentGrade'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Percentage count summary of Incident Grade classes\n","train_data['IncidentGrade'].value_counts() * 100 / train_data['IncidentGrade'].shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["## Data Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# def prepare_data():\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["le_cat_columns = ['Category', 'EntityType', 'EvidenceRole', 'SuspicionLevel', 'LastVerdict',\n","                  'ResourceType', 'Roles', 'AntispamDirection', 'ThreatFamily','CountryCode',\n","                  'OSFamily', 'OSVersion','State', 'City', 'RegistryValueName', 'RegistryValueData', \n","                  'ResourceIdName', 'RegistryKey', 'OAuthApplicationId', 'ApplicationId', 'ApplicationName']\n","\n","numerical_columns = ['DeviceId', 'Sha256', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn', 'AccountObjectId',\n","                     'AccountName', 'DeviceName', 'NetworkMessageId', 'EmailClusterId', 'FileName', 'FolderPath']\n","\n","le_cat_columns += numerical_columns\n","\n","numerical_columns = []\n","\n","ohe_cat_columns = []"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data[le_cat_columns].nunique().sort_values(ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data[numerical_columns].nunique().sort_values(ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Inspect columns with number of unique values less than 10\n","for col in train_data:\n","    if train_data[col].nunique() < 10:\n","        print(col, train_data[col].unique())"]},{"cell_type":"markdown","metadata":{},"source":["## Data Exploration"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def preprocess_data(df, le_cat_columns):\n","    \"\"\"\n","        This function preprocesses the dataset\n","    \"\"\"\n","    \n","    # Converts columns with fewer than 20 unique values to ohe categorical columns\n","    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n","    \n","    # Converts numerical to label encoded categorical columns\n","    for le_col in le_cat_columns:\n","        df[le_col] = df[le_col].astype('object')\n","\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data = preprocess_data(train_data, le_cat_columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(train_data[le_cat_columns].nunique())\n","print(train_data[ohe_cat_columns].nunique())\n","print(train_data[numerical_columns].nunique())"]},{"cell_type":"markdown","metadata":{},"source":["### ANOVA F-Statistic\n","\n","**Goal**: To assess the statistical significance of a feature in predicting the target variable.\n","\n","After encoding the categorical features as numerical values, ANOVA (Analysis of Variance) is used to measure the significance of each feature.\n","\n","**Method:**\n","\n","ANOVA compares the means of different groups and determines if the differences between those means are statistically significant.\n","The larger the F-statistic, the more significant the feature is as a predictor.\n","\n","**Findings:**\n","\n","* **Country Code**, **State** and **City**  are the most significant predictors.\n","* **Resource Type**, **RegistryValueName**, **RegistryValueData**, **Roles** do not appear to have strong significance as predictors.\n","\n","To assess the statistical significance of a feature on the target variable.\n","\n","After the categorical feature is encoded as numerical values, ANOVA is used to measure the significance of the feature."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.feature_selection import f_classif\n","\n","cat_columns = ohe_cat_columns + le_cat_columns\n","\n","# stats_data = pd.DataFrame()\n","\n","for cat in cat_columns:\n","    # One-Hot Encode the categorical data\n","    onehot_encoder = OneHotEncoder(sparse_output=False)  # Adjust for the FutureWarning\n","    X_encoded = onehot_encoder.fit_transform(train_data[[cat]])  # Use double brackets to pass a 2D array\n","    \n","    # ANOVA F-Statistic\n","    label_encoder = LabelEncoder()\n","    y = label_encoder.fit_transform(train_data['IncidentGrade'])  # Assuming IncidentGrade is categorical\n","    f_statistic, p_value = f_classif(X_encoded, y)\n","    \n","    print(\"*\" * 20)\n","    print(f\"Feature: {cat}\")\n","    print(f\"ANOVA F-Statistic: {f_statistic}\")\n","    print(f\"p-Value: {p_value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Convert 'Timestamp' column to datetime\n","train_data['Timestamp'] = pd.to_datetime(train_data['Timestamp'])\n","\n","train_data.info()"]},{"cell_type":"markdown","metadata":{},"source":["## Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["def process_data():\n","    train_data = pd.read_csv(\"c:\\Users\\Abhinav sinha\\OneDrive\\Desktop\\OSData_Train .csv\") \n","    test_data = pd.read_csv(\"C:\\Users\\Abhinav sinha\\OneDrive\\Desktop\\OSData_Test.csv\")\n","    \n","    print(train_data.shape)\n","    \n","    # Drop rows with missing target variable 'IncidentGrade'\n","    train_data.dropna(subset=['IncidentGrade'], inplace=True)\n","    \n","    train_data = preprocess_data(train_data, le_cat_columns)\n","    test_data = preprocess_data(test_data, le_cat_columns)\n","    \n","    group_columns = ohe_cat_columns + numerical_columns + le_cat_columns\n","    \n","    # Drop duplicates based on the specified columns\n","    train_data = train_data.drop_duplicates(subset=group_columns)\n","    \n","    # Drop usage column as it is not present in train dataset\n","    test_data.drop(['Usage'], axis=1, inplace=True)\n","    \n","    print(train_data.shape)\n","    print(test_data.shape)\n","    \n","    #  One hot encoding\n","    ohe = OneHotEncoder(handle_unknown='ignore')\n","    ohe.fit(train_data[ohe_cat_columns])\n","\n","    train_data_ohe = csr_matrix(ohe.transform(train_data[ohe_cat_columns]))\n","    test_data_ohe = csr_matrix(ohe.transform(test_data[ohe_cat_columns]))\n","\n","    # Fill NaNs for numerical columns\n","    train_data_numerical = csr_matrix(train_data[numerical_columns].fillna(-1).values)\n","    test_data_numerical = csr_matrix(test_data[numerical_columns].fillna(-1).values)\n","    \n","    # Feature label encoding\n","    feature_le = LabelEncoder()\n","    \n","    train_data_le = pd.DataFrame()\n","    test_data_le = pd.DataFrame()\n","    \n","    # Fit and transform the feature variables\n","    for le_col in le_cat_columns:\n","        # we want to stack train and test for label encoding of some cat variables\n","        feature_le.fit(pd.concat([train_data[le_col], test_data[le_col]]))\n","        train_data_le[le_col] = feature_le.transform(train_data[le_col])\n","        test_data_le[le_col] = feature_le.transform(test_data[le_col])\n","    \n","    train_data_le = csr_matrix(train_data_le)\n","    test_data_le = csr_matrix(test_data_le)\n","    \n","    X_train = hstack([train_data_ohe, train_data_le ,train_data_numerical])\n","    X_test = hstack([test_data_ohe, test_data_le, test_data_numerical])\n","\n","    # Target label encoding\n","    target_le = LabelEncoder()\n","    \n","    # Fit and transform the target variable\n","    target_le.fit(train_data['IncidentGrade'])\n","    y_train = target_le.transform(train_data['IncidentGrade'])\n","    y_test = target_le.transform(test_data['IncidentGrade'])\n","    \n","    # Print out the label classes of the target variable\n","    \"\"\"\n","        0: 'BenignPositive'\n","        1: 'FalsePositive'\n","        2: 'TruePositive'\n","    \"\"\"\n","    print(f\"Target Classes: {target_le.classes_}\")\n","        \n","    return X_train, y_train, X_test, y_test\n","    \n","    \n","# get the data\n","X_train, y_train, X_test, y_test = process_data()"]},{"cell_type":"markdown","metadata":{},"source":["## Modeling and Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, auc\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","def predict(model, X_test, y_test):\n","    # Generate predictions\n","    y_pred = model.predict(X_test)\n","    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n","    \n","    # Print accuracy\n","    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n","    \n","    # Print classification report\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(y_test, y_pred))\n","    \n","    # Print confusion matrix\n","    print(\"\\nConfusion Matrix:\")\n","    \n","    cm = confusion_matrix(y_test, y_pred)\n","    \n","    cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, \n","                                        display_labels = ['BenignPositive', 'FalsePositive', 'TruePositive'])\n","\n","    cm_display.plot()\n","    plt.show()\n","\n","    return y_pred"]},{"cell_type":"markdown","metadata":{},"source":["### Random Forest Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_random_forest_classifier(X_train, y_train):\n","    model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n","    \n","    model.fit(X_train, y_train)\n","    \n","    # Feature importance\n","    importances = model.feature_importances_\n","    \n","    feature_columns = np.array(ohe_cat_columns + le_cat_columns + numerical_columns)\n","    \n","    # Plot feature importance\n","    indices = np.argsort(importances)[::-1]\n","    \n","    plt.figure(figsize=(12, 6))\n","    plt.title(\"Feature Importances (Random Forest Classifier)\")\n","    plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n","    plt.xticks(range(X_train.shape[1]), feature_columns[indices], rotation=90)\n","    plt.xlim([-1, X_train.shape[1]])\n","    plt.show()\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# train a random forest classifier model\n","rfc_model = train_random_forest_classifier(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# make predictions\n","y_pred = predict(rfc_model, X_test, y_test)\n","\n","# evaluate test performance\n","accuracy = accuracy_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred, average='macro')\n","precision = precision_score(y_test, y_pred, average='macro')\n","\n","f1 = f1_score(y_test, y_pred, average='macro')\n","\n","print('Accuracy: {}'.format(accuracy))\n","print('Macro-Precision: {}'.format(precision))\n","print('Macro-Recall: {}'.format(recall))\n","print('Macro-F1 Score: {}'.format(f1))"]},{"cell_type":"markdown","metadata":{},"source":["### XGBoost Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from xgboost import XGBClassifier\n","\n","def train_xgboost_classifier(X_train, y_train):\n","    model = XGBClassifier(n_estimators=100, max_depth=5, random_state=0, use_label_encoder=False, eval_metric='mlogloss')\n","    \n","    model.fit(X_train, y_train)\n","    \n","    # Feature importance\n","    importances = model.feature_importances_\n","    \n","    feature_columns = np.array(ohe_cat_columns + le_cat_columns + numerical_columns)\n","    \n","    # Plot feature importance\n","    indices = np.argsort(importances)[::-1]\n","    \n","    plt.figure(figsize=(12, 6))\n","    plt.title(\"Feature Importances (XGBoost Classifier)\")\n","    plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n","    plt.xticks(range(X_train.shape[1]), feature_columns[indices], rotation=90)\n","    plt.xlim([-1, X_train.shape[1]])\n","    plt.show()\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# train a random forest classifier model\n","xgb_model = train_xgboost_classifier(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# make predictions\n","y_pred = predict(xgb_model, X_test, y_test)\n","\n","# evaluate test performance\n","accuracy = accuracy_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred, average='macro')\n","precision = precision_score(y_test, y_pred, average='macro')\n","f1 = f1_score(y_test, y_pred, average='macro')\n","\n","print('Accuracy: {}'.format(accuracy))\n","print('Macro-Precision: {}'.format(precision))\n","print('Macro-Recall: {}'.format(recall))\n","print('Macro-F1 Score: {}'.format(f1))"]},{"cell_type":"markdown","metadata":{},"source":["### CatBoost"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from catboost import CatBoostClassifier\n","\n","def train_catboost_classifier(X_train, y_train):\n","    model = CatBoostClassifier(iterations=100, depth=5, random_seed=0, verbose=0)\n","    \n","    model.fit(X_train, y_train)\n","    \n","    # Feature importance\n","    importances = model.get_feature_importance()\n","    \n","    feature_columns = np.array(ohe_cat_columns + le_cat_columns + numerical_columns)\n","    \n","    # Plot feature importance\n","    indices = np.argsort(importances)[::-1]\n","    \n","    plt.figure(figsize=(12, 6))\n","    plt.title(\"Feature Importances (CatBoost Classifier)\")\n","    plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n","    plt.xticks(range(X_train.shape[1]), feature_columns[indices], rotation=90)\n","    plt.xlim([-1, X_train.shape[1]])\n","    plt.show()\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# train a random forest classifier model\n","cat_model = train_catboost_classifier(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# make predictions\n","y_pred = predict(cat_model, X_test, y_test)\n","\n","# evaluate test performance\n","accuracy = accuracy_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred, average='macro')\n","precision = precision_score(y_test, y_pred, average='macro')\n","f1 = f1_score(y_test, y_pred, average='macro')\n","\n","print('Accuracy: {}'.format(accuracy))\n","print('Macro-Precision: {}'.format(precision))\n","print('Macro-Recall: {}'.format(recall))\n","print('Macro-F1 Score: {}'.format(f1))"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5371198,"sourceId":8929038,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
